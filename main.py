import re
import sys
import os
import json
import logging
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
from ics import Calendar, Event
from playwright.sync_api import sync_playwright
from dotenv import load_dotenv
from collections import defaultdict

from rich.console import Console
from rich.table import Table
from rich import box
from rich.text import Text
from rich.console import Group

load_dotenv()

# --- –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Ø ---
URL = os.getenv("LOE_URL", "https://poweron.loe.lviv.ua/")
OUTPUT_DIR = os.getenv("OUTPUT_DIR", "schedules")
STATE_FILE = os.path.join(OUTPUT_DIR, "schedule_state.json")
HISTORY_FILE = os.path.join(OUTPUT_DIR, "history.json")
TZ = ZoneInfo(os.getenv("TIMEZONE", "UTC"))

env_groups = os.getenv("GROUPS", "1.1,1.2,2.1,2.2,3.1,3.2,4.1,4.2,5.1,5.2,6.1,6.2")
ALL_GROUPS = [g.strip() for g in env_groups.split(",") if g.strip()]

console = Console()
logging.basicConfig(
    level=logging.INFO, format="%(message)s", handlers=[logging.StreamHandler()]
)


# --- –†–û–ë–û–¢–ê –ó –§–ê–ô–õ–ê–ú–ò ---
def load_json(filepath):
    if os.path.exists(filepath):
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}


def save_json(filepath, data):
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception:
        pass


def update_history(date_str, group, seconds_off, intervals_list):
    history = load_json(HISTORY_FILE)

    if date_str not in history:
        history[date_str] = {}

    history[date_str][group] = {
        "total_seconds": seconds_off,
        "intervals": intervals_list,
    }

    save_json(HISTORY_FILE, history)


# --- –õ–û–ì–Ü–ö–ê –ß–ê–°–£ ---
def parse_time_aware(date_obj, time_str):
    if time_str == "24:00":
        dt_naive = datetime.combine(date_obj + timedelta(days=1), datetime.min.time())
    else:
        parsed_time = datetime.strptime(time_str, "%H:%M").time()
        dt_naive = datetime.combine(date_obj, parsed_time)
    return dt_naive.replace(tzinfo=TZ)


def format_timedelta_hours(td: timedelta):
    total_seconds = int(td.total_seconds())
    hours = total_seconds // 3600
    minutes = (total_seconds % 3600) // 60
    return f"{hours}–≥ {minutes:02d}—Ö–≤"


def format_seconds_nice(seconds):
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    return f"{hours}–≥ {minutes:02d}—Ö–≤"


def get_intervals_signature(intervals):
    sigs = []
    for start, end in intervals:
        sigs.append(f"{start.strftime('%H:%M')}-{end.strftime('%H:%M')}")
    return "|".join(sigs)


# --- –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø ---
def create_visual_timeline_with_ruler(blackout_intervals):
    slots = [False] * 48
    for start, end in blackout_intervals:
        start_idx = start.hour * 2 + (1 if start.minute >= 30 else 0)
        if end.hour == 0 and end.minute == 0 and end.day > start.day:
            end_idx = 48
        else:
            end_idx = end.hour * 2 + (1 if end.minute >= 30 else 0)

        for i in range(start_idx, end_idx):
            if i < 48:
                slots[i] = True

    ruler = Text()
    bar = Text()
    hours_labels = ["00", "04", "08", "12", "16", "20"]

    for i in range(0, 48, 8):
        if i > 0:
            ruler.append("‚îÇ", style="dim white")
            bar.append("‚îÇ", style="dim white")
        label_idx = i // 8
        label = hours_labels[label_idx] if label_idx < len(hours_labels) else "  "
        ruler.append(f"{label:<8}", style="dim white")

        chunk = slots[i : i + 8]
        for is_blackout in chunk:
            if is_blackout:
                bar.append("‚ñà", style="red")
            else:
                bar.append("‚ñà", style="green dim")
    ruler.append("‚îÇ24", style="dim white")
    bar.append("‚îÇ", style="dim white")
    return Group(ruler, bar)


# --- –û–°–ù–û–í–ù–ê –õ–û–ì–Ü–ö–ê ---
def generate_calendar_for_group(group_id, target_date, text_content):
    cal = Calendar()
    group_pattern = (
        rf"–ì—Ä—É–ø–∞ {re.escape(group_id)}\. –ï–ª–µ–∫—Ç—Ä–æ–µ–Ω–µ—Ä–≥—ñ—ó –Ω–µ–º–∞—î (.*?)(?:\n|–ì—Ä—É–ø–∞|$)"
    )
    group_match = re.search(group_pattern, text_content, re.DOTALL)

    blackout_intervals = []
    interval_strings = []
    total_blackout_duration = timedelta(0)

    if group_match:
        raw_intervals = group_match.group(1).strip()
        time_ranges = re.findall(r"–∑ (\d{2}:\d{2}) –¥–æ (\d{2}:\d{2})", raw_intervals)
        for start_str, end_str in time_ranges:
            interval_strings.append(f"{start_str}-{end_str}")
            start_dt = parse_time_aware(target_date, start_str)
            end_dt = parse_time_aware(target_date, end_str)
            if end_dt < start_dt:
                end_dt += timedelta(days=1)

            total_blackout_duration += end_dt - start_dt
            blackout_intervals.append((start_dt, end_dt))
            cal.events.add(
                Event(
                    name="üåë –ù–µ–º–∞ —Å–≤—ñ—Ç–ª–∞",
                    begin=start_dt,
                    end=end_dt,
                    description=f"–ì—Ä—É–ø–∞ {group_id}",
                )
            )

    blackout_intervals.sort(key=lambda x: x[0])

    day_start = datetime.combine(target_date, datetime.min.time()).replace(tzinfo=TZ)
    day_end = day_start + timedelta(days=1)
    current_time = day_start

    for b_start, b_end in blackout_intervals:
        if current_time < b_start:
            cal.events.add(Event(name="üí° –Ñ —Å–≤—ñ—Ç–ª–æ", begin=current_time, end=b_start))
        current_time = max(current_time, b_end)
    if current_time < day_end:
        cal.events.add(Event(name="üí° –Ñ —Å–≤—ñ—Ç–ª–æ", begin=current_time, end=day_end))

    visual_group = create_visual_timeline_with_ruler(blackout_intervals)
    current_signature = get_intervals_signature(blackout_intervals)
    percent_off = (total_blackout_duration.total_seconds() / 86400) * 100

    statistics = {
        "visual_group": visual_group,
        "intervals_display_str": (
            "\n".join(interval_strings) if interval_strings else "[green]–°–≤—ñ—Ç–ª–æ —î[/]"
        ),
        "intervals_list": interval_strings,
        "intervals_signature": current_signature,
        "total_off": total_blackout_duration,
        "percent_off": percent_off,
    }
    return cal, statistics


def print_historical_stats():
    history = load_json(HISTORY_FILE)
    if not history:
        return

    group_stats = defaultdict(list)
    total_days = len(history)

    for date_str, day_data in history.items():
        for group, data in day_data.items():
            if group not in ALL_GROUPS:
                continue

            seconds = 0
            if isinstance(data, (int, float)):
                seconds = data
            elif isinstance(data, dict):
                seconds = data.get("total_seconds", 0)

            group_stats[group].append(seconds)

    table = Table(
        title=f"üìä –ó–≤–µ–¥–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–î–Ω—ñ–≤ –≤ –±–∞–∑—ñ: {total_days})", box=box.DOUBLE_EDGE
    )
    table.add_column("–ì—Ä—É–ø–∞", style="cyan bold", justify="center")
    table.add_column("–°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å", justify="right")
    table.add_column("–ú–∞–∫—Å–∏–º—É–º", justify="right", style="red")
    table.add_column("–£—Å—å–æ–≥–æ (—Å—É–º–∞)", justify="right", style="dim")

    for group in ALL_GROUPS:
        values = group_stats.get(group, [])
        if not values:
            continue

        avg_seconds = sum(values) / len(values)
        max_seconds = max(values)
        total_seconds = sum(values)

        table.add_row(
            group,
            format_seconds_nice(avg_seconds),
            format_seconds_nice(max_seconds),
            f"{total_seconds // 3600:.0f} –≥–æ–¥",
        )

    console.print("\n")
    console.print(table)


def main():
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    state = load_json(STATE_FILE)

    with console.status("[bold green]–û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö...", spinner="dots"):
        page_text = ""
        with sync_playwright() as p:
            try:
                browser = p.chromium.launch(headless=True)
                page = browser.new_page()
                page.goto(URL)
                page.wait_for_selector(
                    "text=–ì—Ä–∞—Ñ—ñ–∫ –ø–æ–≥–æ–¥–∏–Ω–Ω–∏—Ö –≤—ñ–¥–∫–ª—é—á–µ–Ω—å", timeout=15000
                )
                page_text = page.inner_text("body")
                browser.close()
            except Exception as e:
                console.print(f"[bold red]Error:[/bold red] {e}")
                sys.exit(1)

    header_pattern = re.compile(
        r"–ì—Ä–∞—Ñ—ñ–∫ –ø–æ–≥–æ–¥–∏–Ω–Ω–∏—Ö –≤—ñ–¥–∫–ª—é—á–µ–Ω—å –Ω–∞ (\d{2}\.\d{2}\.\d{4})"
    )
    matches = list(header_pattern.finditer(page_text))
    if not matches:
        console.print("[bold red]–ì—Ä–∞—Ñ—ñ–∫—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ![/]")
        sys.exit(1)

    schedules = []
    for i, match in enumerate(matches):
        try:
            d = datetime.strptime(match.group(1), "%d.%m.%Y").date()
            end_idx = matches[i + 1].start() if i + 1 < len(matches) else len(page_text)
            schedules.append((d, page_text[match.end() : end_idx]))
        except ValueError:
            continue

    schedules.sort(key=lambda x: x[0], reverse=True)
    target_date, target_text = schedules[0]
    target_date_str = target_date.strftime("%Y-%m-%d")

    update_match = re.search(r"–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —Å—Ç–∞–Ω–æ–º –Ω–∞\s+(.*?)(?:\n|$)", target_text)
    last_updated = update_match.group(1).strip() if update_match else "–ù–µ–≤—ñ–¥–æ–º–æ"

    console.print(
        f"\nüìÖ [bold cyan]–î–∞—Ç–∞ –≥—Ä–∞—Ñ—ñ–∫—É:[/bold cyan] {target_date}  |  üïí [dim]–û–Ω–æ–≤–ª–µ–Ω–æ: {last_updated}[/dim]\n"
    )

    table = Table(
        title="–ì—Ä–∞—Ñ—ñ–∫ –Ω–∞ —Å—å–æ–≥–æ–¥–Ω—ñ (4-–≥–æ–¥–∏–Ω–Ω–∞ —Å—ñ—Ç–∫–∞)",
        box=box.ROUNDED,
        pad_edge=False,
        show_lines=True,
    )

    table.add_column("–ì—Ä—É–ø–∞", justify="center", style="cyan bold", no_wrap=True)
    table.add_column("–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è", justify="left")
    table.add_column("–ì–æ–¥–∏–Ω–∏", style="white")
    table.add_column("–°—å–æ–≥–æ–¥–Ω—ñ", justify="right")
    table.add_column("–°—Ç–∞—Ç—É—Å", justify="center")

    new_state = {"date": target_date_str, "groups": {}}

    for group in ALL_GROUPS:
        cal, stats = generate_calendar_for_group(group, target_date, target_text)

        with open(
            os.path.join(OUTPUT_DIR, f"group_{group}.ics"), "w", encoding="utf-8"
        ) as f:
            f.writelines(cal.serialize_iter())

        sig = stats["intervals_signature"]
        new_state["groups"][group] = sig

        update_history(
            target_date_str,
            group,
            stats["total_off"].total_seconds(),
            stats["intervals_list"],
        )

        prev_date = state.get("date")
        status_str = "[dim]–ë–µ–∑ –∑–º—ñ–Ω[/dim]"
        if prev_date != target_date_str:
            status_str = "[bold blue]–ù–æ–≤–∏–π –¥–µ–Ω—å[/]"
        elif state.get("groups", {}).get(group) != sig:
            status_str = "[bold red blink]‚ö†Ô∏è –ó–ú–Ü–ù–ê![/]"

        pct = stats["percent_off"]
        color = "red" if pct > 50 else ("yellow" if pct > 30 else "green")
        stats_text = (
            f"{format_timedelta_hours(stats['total_off'])}\n[{color}]{pct:.0f}% –¥–æ–±–∏[/]"
        )

        table.add_row(
            group,
            stats["visual_group"],
            stats["intervals_display_str"],
            stats_text,
            status_str,
        )

    console.print(table)
    save_json(STATE_FILE, new_state)

    print_historical_stats()
    console.print(f"\n[dim]–î–µ—Ç–∞–ª—å–Ω–∞ —ñ—Å—Ç–æ—Ä—ñ—è –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –≤: {HISTORY_FILE}[/dim]")


if __name__ == "__main__":
    main()
